{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook applies the moving region segmentation analysis to a single experiment. Each experiment contains hbec cilia cells from the same culture, and the same concentration of medium (mucin) is used. Within an experiment groups of cells have been subjected to knock down of various genes using CRISPR. The groups are:\n",
    "\n",
    "- Negative control (NT)\n",
    "- fam13a gAA\n",
    "- fam13a g1\n",
    "- Positive control (DNA_gAA)\n",
    "\n",
    "An experiment contains videos from up to 24 wells, and each of those videos contain multiple replicates of the groups mentioned above. The videos record the movement of fluorescent beads, at a frame rate of 10fps.\n",
    "\n",
    "NOTE: the entire experiment must be processed at the same time as threshold value calculated is global across all the videos in a single experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving Region Segmentation\n",
    "\n",
    "In this notebook, the moving regions for each well are identified and saved as arrays for further processing. The steps in this calculation are as follows:\n",
    "\n",
    "For each video of each well a region-of-interest (ROI) and max-frame are identified The ROI indicates the boundaries of the well. The max-frame provides the maximum intensity porjection across the time axis. \n",
    "\n",
    "1. ROI calculation\n",
    "    - the frame with the highest brightness is passed to the function `image.roi.circle`. This function uses the Sobel operator and Hough transform to return the ROI.\n",
    "2. Max frame calculation\n",
    "    - For each video, take the brightest pixel across frames (so the time dimension) to obtain a static image with the maximum projection view.\n",
    "    - Subtract the median across all frames and time points to remove background noise\n",
    "    - Use an Otsu threshold to split the pixels in the image into two classes, highlighting trails of movement\n",
    "    - The area of moving region is filled in using an averaging algorithm described in the `segment` function\n",
    "3. combine the two masks obtained above to return the moving region mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from tqdm import tqdm\n",
    "import skimage\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from fam13a import consts, utils, track, image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Declare constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJ_ROOT = utils.here()\n",
    "# declare the data input directory\n",
    "HBEC_ROOT = os.path.join(PROJ_ROOT, 'data', 'interim', 'hbec')\n",
    "\n",
    "print(os.listdir(HBEC_ROOT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the experiment data to process\n",
    "EXP_ID = 'N67030-59_ON'\n",
    "# declare the various output directories\n",
    "DATA_ROOT = os.path.join(HBEC_ROOT, EXP_ID)\n",
    "EXP_ROOT = os.path.join(PROJ_ROOT, 'data', 'processed', 'hbec', EXP_ID)\n",
    "\n",
    "ROI_OUTPUT_ROOT = os.path.join(EXP_ROOT, 'roi')\n",
    "SEG_OUTPUT_ROOT = os.path.join(EXP_ROOT, 'segmented', 'movement')\n",
    "NOISY_OUTPUT_ROOT = os.path.join(EXP_ROOT, 'segmented', 'noisy')\n",
    "MAX_FRAME_OUTPUT_ROOT = os.path.join(EXP_ROOT, 'max_frame')\n",
    "\n",
    "for root in [ROI_OUTPUT_ROOT, SEG_OUTPUT_ROOT, NOISY_OUTPUT_ROOT, MAX_FRAME_OUTPUT_ROOT]:\n",
    "    os.makedirs(root, exist_ok=True)\n",
    "\n",
    "# set level of parallelisation\n",
    "NCPUS = 7\n",
    "# define the common file extension used in the input data files\n",
    "EXTENSION = '.ome.tif'\n",
    "\n",
    "# find all relevant data files in the data directory \n",
    "files = sorted([_f for _f in os.listdir(DATA_ROOT) if _f.endswith('tif')])\n",
    "# remove the extension the file names, se we keep only the bit with useful information\n",
    "files = [_f.split(EXTENSION)[0] for _f in files]\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "Define some helper functions for convienence and to facilitate parallelisation. These are not declared in `src` as they are tightly coupled to this segmentation process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(_file):\n",
    "    frames = utils.frames_from_stack(os.path.join(DATA_ROOT, f'{_file}{EXTENSION}'))\n",
    "    # find the ROI assuming it is a circle\n",
    "    roi = image.roi.circle(frames.max(axis=0))\n",
    "    \n",
    "    # extract the maximal projection of the video \n",
    "    # the median is used as an estimate of background in the video\n",
    "    # it is subtracted in order to emphasise the moving regions of the video\n",
    "    max_frame = np.max(frames, axis=0) - np.median(frames, axis=0)\n",
    "    return roi, max_frame\n",
    "\n",
    "\n",
    "def segment(_file, roi, max_frame, thresh_value):\n",
    "    \n",
    "    # apply the OTSU threshold and set all pixels outside the ROI to 0 \n",
    "    noisy_mask = (max_frame > thresh_value)\n",
    "    noisy_mask[~roi] = 0\n",
    "    \n",
    "    # we now need to cleanup the mask, and to do this we take overlapping patches from the noisy mask\n",
    "    # then for each patch if a large enough portion is segmented we set the whole patch to be segmented\n",
    "    # then recombine all patches, with the overlaps giving multiple predictions (segmented or not) per pixel\n",
    "    # and take the average of all those predictions\n",
    "    \n",
    "    # use 'reflect' mode to account for patches at the boundary of the image, want to get a consistent number\n",
    "    # of overlaps for each pixel\n",
    "    patched_mask = image.patch.extract(noisy_mask, image.consts.HBEC_WINDOW_SIZE,\n",
    "                                       image.consts.HBEC_STEPS_SIZE, mode='reflect')\n",
    "    # for each patch calculate the segmentation ratio and then threshold\n",
    "    # this gives a prediction for the entire patch of segmented or not\n",
    "    for idx, patch in enumerate(patched_mask):\n",
    "        patched_mask[idx] = patch.sum()/patch.size > image.consts.HBEC_RATIO_PER_PATCH_THRESH\n",
    "    patched_mask = patched_mask.astype(int)\n",
    "    \n",
    "    # merge the patches back into a single image, taking the average value for overlapping pixels\n",
    "    merged = image.patch.merge(patched_mask, noisy_mask.shape, image.consts.HBEC_STEPS_SIZE, padded=True)\n",
    "    # round the averaged pixel values, \n",
    "    # i.e. if atleast 1/2 of all predictions mark the pixel as segmented then it is\n",
    "    merged = np.round(merged)\n",
    "    \n",
    "    # save the max_frame, ROI, initial segmentation, and cleaned segmentation as numpy arrays\n",
    "    np.save(os.path.join(SEG_OUTPUT_ROOT, f'{_file}.npy'), merged)\n",
    "    np.save(os.path.join(ROI_OUTPUT_ROOT, f'{_file}.npy'), roi)\n",
    "    np.save(os.path.join(MAX_FRAME_OUTPUT_ROOT, f'{_file}.npy'), max_frame)\n",
    "    np.save(os.path.join(NOISY_OUTPUT_ROOT, f'{_file}.npy'), noisy_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the ROI and max_frame from each video\n",
    "# parallelise the processing across the different files/videos\n",
    "# with NCPUS=7, the total time to run across 24 wells is 9 min\n",
    "with Parallel(n_jobs=NCPUS, verbose=20) as par:\n",
    "    cleaned = par(delayed(clean)(_file) for _file in files)\n",
    "\n",
    "# split the ROIs and max_frames into separate lists\n",
    "rois, max_frames = list(zip(*cleaned))\n",
    "# convert list of max_frames into a single numpy array as required by the downstream process\n",
    "max_frames = np.stack(max_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate a global threshold value for all max_frames using the OTSU algorithm \n",
    "thr_val = skimage.filters.threshold_otsu(max_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure all the output directories exist\n",
    "for root in [SEG_OUTPUT_ROOT, ROI_OUTPUT_ROOT, MAX_FRAME_OUTPUT_ROOT, NOISY_OUTPUT_ROOT]:\n",
    "    os.makedirs(os.path.abspath(root), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the segmentation process for each ROI, max_frame pair\n",
    "# parallelised across ROIs/max_frames\n",
    "# with NCPUS=7, the total time to run across 24 wells is 30 sec\n",
    "with Parallel(n_jobs=NCPUS, verbose=20) as par:\n",
    "    par(delayed(segment)(_file, roi, max_frame, thr_val) for _file, roi, max_frame in zip(files, rois, max_frames))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
