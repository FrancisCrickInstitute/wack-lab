{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "The aim of this notebook is to calculate an average velocity vector field for each video in an experiment. The notebook uses the registration process to do this:\n",
    "\n",
    "1. Each frame in a video is split up into regions of size `REGION_SIZE` (e.g. (9,9) ). Within the centre of each region a pattern is isolated of size `PTRN_SIZE` (e.g. (5,5) ).\n",
    "    - At time step *T*, the pattern in a region is isolated. \n",
    "    - This pattern is then \"registered\" with another pattern in the same region but at time step *T+1*.\n",
    "    - If a suitable match for the pattern is found, then a vector for the motion is calculated, otherwise a zero-vector is returned.\n",
    "    - Note that the resulting velocity vector field will have a different size to that of the original video. For example, a (2048,2048) frame will result in a (408, 408) velocity vector field.\n",
    "    \n",
    "    <img src=\"markdown_images_for_notebooks/registration-example.PNG\">\n",
    "\n",
    "2. The `MAX_WINDOW` parameter reduces the number of frames in a video. (e.g. `MAX_WINDOW = 5`)\n",
    "    - A maxpool operation is applied every (for example) 5 frames so if the video consists of 300 frames, this is reduce to 60 frames.\n",
    "    - This is done to increase the signal in each aggregate frame to make registration easier \n",
    "    - Signal may need to be increased in cases where beads submerge below the liquid surfaces between frames and then re-emerge\n",
    "    \n",
    "    \n",
    "3. The errors associated with the registration process have also been identified and studied further in this [Notebook: 1_errors_in_registration](auxiliary_analysis/1_errors_in_registration.ipynb)\n",
    "\n",
    "    - The registration process in the current notebook is carried out for both the forwards and backwards time directions\n",
    "    - In theory, if the process is successful the equal but opposite vector field for the backwards time direction video should be returned. \n",
    "    - The validation of the registration process can be found in this [Notebook: 3_validate_registration](auxiliary_analysis/3_validate_registration.ipynb)\n",
    "    \n",
    "\n",
    "4. In total, there are 3 adjustable parameters that can be tuned: `REGION_SIZE`, `PTRN_SIZE`, `MAX_WINDOW`\n",
    "    \n",
    "    - These parameters can vary from one experiment to another. As mentioned above, the combination of `REGION_SIZE` and `PTRN_SIZE` sets a limit on the maximum velocity vector that can be calculated\n",
    "    - `MAX_WINDOW` can also be varied - there maybe some experiments where beads tend not to sub merge below the liquid surface and so maxpooling across frames may not be required\n",
    "    - Additionally, if the beads are slow moving in an experiment, then rather than maxpooling across frames, it may be more beneficial to simply skip frames.\n",
    "    - The tuning of these parameters is carried out in this [Notebook: 2_minimise_error_in_registration](auxiliary_analysis/2_minimise_error_in_registration.ipynb). This notebook must be run for each experiment separately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import signal\n",
    "import skimage\n",
    "from skimage import morphology as sk_morph\n",
    "from skimage import exposure\n",
    "import os\n",
    "import json\n",
    "\n",
    "from IPython import display\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from tqdm import tqdm\n",
    "\n",
    "from fam13a import utils, image, register\n",
    "from multiprocessing import Pool\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJ_ROOT = utils.here()\n",
    "# declare the data input directory\n",
    "INTERIM_HBEC_ROOT = os.path.join(PROJ_ROOT, 'data', 'interim', 'hbec')\n",
    "print(os.listdir(INTERIM_HBEC_ROOT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose experiment data to load\n",
    "EXP_ID = 'N67030-59_8_perc'\n",
    "\n",
    "INTERIM_ROOT = os.path.join(PROJ_ROOT, INTERIM_HBEC_ROOT, EXP_ID)\n",
    "\n",
    "# declare the various output directories\n",
    "PROCESSED_ROOT = os.path.join(PROJ_ROOT, 'data', 'processed', 'hbec', EXP_ID)\n",
    "ROI_ROOT = os.path.join(PROCESSED_ROOT, 'roi')\n",
    "SEG_ROOT = os.path.join(PROCESSED_ROOT, 'segmented', 'movement')\n",
    "MAX_FRAME_ROOT = os.path.join(PROCESSED_ROOT, 'max_frame')\n",
    "\n",
    "OUTPUT_ROOT = os.path.join(PROCESSED_ROOT, 'register')\n",
    "# set level of parallelisation\n",
    "NCPUS = 32\n",
    "# define the common file extension used in the input data files\n",
    "EXTENSION = '.ome.tif'\n",
    "\n",
    "# find all relevant data files in the data directory \n",
    "files = sorted([_f for _f in os.listdir(INTERIM_ROOT) if _f.endswith('tif')])\n",
    "# remove the extension the file names, se we keep only the bit with useful information\n",
    "files = [_f.split(EXTENSION)[0] for _f in files]\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "Set registration parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# window size to take along the time dimension\n",
    "MAX_WINDOW = 5\n",
    "# set the sizes of the pattern and search regions\n",
    "PTRN_SIZE = (5,)*2\n",
    "REGION_SIZE = (9,)*2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "defining a very simple wrapper around the register.estimate_shifts functon purely to allow the inclusion of a progress bar during processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process\n",
    "\n",
    "- For each video, calculate the shifts in both the forwards and backwards time directions\n",
    "- NOTE: it takes ~60 seconds to process 1 pair of frames on 1 CPU\n",
    "- with NCPUS=32, time is 65 min (for a 24 well experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, _file in enumerate(files):\n",
    "    print(f'starting: {_file} ({idx+1} of {len(files)})')\n",
    "    \n",
    "    # load the frames and create forwards and backwards in time copies\n",
    "    frames = utils.frames_from_stack(os.path.join(INTERIM_ROOT, f'{_file}{EXTENSION}'))\n",
    "    frames_forwards = frames.copy()\n",
    "    frames_backwards = frames.copy()[::-1]\n",
    "    # load each of the pther associated interim/processed files\n",
    "    roi = np.load(os.path.join(ROI_ROOT, f'{_file}.npy'))\n",
    "    max_frame = np.load(os.path.join(MAX_FRAME_ROOT, f'{_file}.npy'))\n",
    "    movement_mask = np.load(os.path.join(SEG_ROOT, f'{_file}.npy')).astype(bool)\n",
    "    \n",
    "    # need to run the reg process forwards and backwards in time - only need the \n",
    "    # backwards shifts since the unpad-slice and sub-shape variables are independent\n",
    "    # of time direction\n",
    "    reg_process_forwards = register.run_registration_process(\n",
    "        frames_forwards, MAX_WINDOW, PTRN_SIZE, REGION_SIZE, NCPUS\n",
    "    )\n",
    "    shifts_forwards = reg_process_forwards['shifts']\n",
    "    reg_process_backwards = register.run_registration_process(\n",
    "        frames_backwards, MAX_WINDOW, PTRN_SIZE, REGION_SIZE, NCPUS\n",
    "    )\n",
    "    shifts_backwards = reg_process_backwards['shifts']\n",
    "    \n",
    "    # given the forwards and backwards shifts, we can caluclate the average velocity field\n",
    "    # then we can calculate the angles between the vectors in the positive forwards \n",
    "    # velocity field and (negative) backwards velocity field.\n",
    "    # So a small angle would correspond to a succesful registration process and a large\n",
    "    # angle above some threshold would correspond to an unsuccesful registration process.\n",
    "    velocity_forwards = register.calculate_mean_velocity_field(shifts_forwards)['normalised_velocity']\n",
    "    velocity_backwards = register.calculate_mean_velocity_field(shifts_backwards)['normalised_velocity']\n",
    "    validation_angles = register.calculate_angles_for_validation(velocity_forwards, velocity_backwards)\n",
    "    \n",
    "    # get the unpad_slice and sub_shape arrays from forwards pass (these\n",
    "    # arrays are independent of time direction)\n",
    "    unpad_slice = reg_process_forwards['unpad_slice']\n",
    "    sub_shape = reg_process_forwards['sub_shape']\n",
    "    \n",
    "    # construct the downsampled movement mask\n",
    "    sub_mask = image.patch.extract(movement_mask[unpad_slice, unpad_slice], PTRN_SIZE).max(axis=(-1, -2))\n",
    "    sub_mask = sub_mask.reshape(sub_shape, sub_shape).astype(bool)\n",
    "\n",
    "    # construct the downsampled max_frame projection\n",
    "    # this projection is used for visualization purposes only\n",
    "    sub_max_frame = frames.max(axis=0)[unpad_slice, unpad_slice]\n",
    "    sub_max_frame = image.patch.extract(sub_max_frame, PTRN_SIZE).max(axis=(-1, -2))\n",
    "    sub_max_frame = sub_max_frame.reshape(sub_shape, sub_shape)\n",
    "    \n",
    "    # construct the downsampled roi mask\n",
    "    sub_roi = image.patch.extract(roi[unpad_slice, unpad_slice], PTRN_SIZE).max(axis=(-1, -2))\n",
    "    sub_roi = sub_roi.reshape(sub_shape, sub_shape).astype(bool)\n",
    "    \n",
    "    # ensure the output directory exists\n",
    "    register_dir = os.path.join(OUTPUT_ROOT, _file)\n",
    "    os.makedirs(register_dir, exist_ok=True)\n",
    "    \n",
    "    # save the calculate frame shifts and downsampled versions of the movement mask and max_frame\n",
    "    np.save(os.path.join(register_dir, 'shifts.npy'), shifts_forwards)\n",
    "    np.save(os.path.join(register_dir, 'reverse_shifts.npy'), shifts_backwards)\n",
    "    np.save(os.path.join(register_dir, 'mask.npy'), sub_mask)    \n",
    "    np.save(os.path.join(register_dir, 'roi.npy'), sub_roi)\n",
    "    np.save(os.path.join(register_dir, 'max_frame.npy'), sub_max_frame)\n",
    "    np.save(os.path.join(register_dir, 'validation_angles.npy'), validation_angles)\n",
    "\n",
    "    # save the registration parameters in the same folder\n",
    "    params = {\n",
    "        'max_window': MAX_WINDOW,\n",
    "        'ptrn_size': PTRN_SIZE,\n",
    "        'region_size': REGION_SIZE\n",
    "    }\n",
    "    with open(os.path.join(register_dir, 'params.json'), 'w') as json_f:\n",
    "        json.dump(params, json_f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
